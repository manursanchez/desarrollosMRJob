{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTE CUADERNO VA FUERA DEL PROYECTO ES SOLO PARA EJEMPLOS Y PRUEBAS \n",
    "\n",
    "Uniones varias: interna, por la izquierda, por la derecha, completa y antiunión. Basado en el libro de Donald Miner y Adam Shook. Este archivo es el ejemplo de donde extraemos todos los algoritmos de unión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile unionesVarias.py\n",
    "#!/usr/bin/env python\n",
    "from mrjob.job import MRJob\n",
    "import re,sys,os\n",
    "\n",
    "class unionesVarias(MRJob):\n",
    "    \n",
    "    #Función que limpia lo que el parámetro devuelve en forma \"file://nombre_fichero\" para dejarlo solo con el nombre \n",
    "    #del fichero: \"nombre_fichero\"\n",
    "    def limpiarNombreArchivo(self,archivo):\n",
    "        tamano=len(archivo)\n",
    "        return archivo[7:tamano]\n",
    "    def mapper_init(self):\n",
    "        self.namefile=self.limpiarNombreArchivo(os.getenv('map_input_file')) #Usamos el parámetro para saber que nos llega desde streaming\n",
    "        #map_input_file devuelve una cadena de caracteres correspondiente al archivo de entrada por el stream en formato:\n",
    "        # file://nombre_fichero\n",
    "        \n",
    "    def mapper(self,_,line):\n",
    "        clave=\"\"\n",
    "        linea=line.split(';')\n",
    "        encontrado=re.search('[a-zA-Z]',linea[0])#Para que no tenga en cuenta las cabeceras de las tablas\n",
    "        if encontrado==None:\n",
    "            if self.namefile==\"tablaA.csv\":\n",
    "                linea.append(self.namefile)#Añadimos al registro el nombre del archivo\n",
    "                clave=linea[0] #Esta clave es la común de la tabla 1, que me permite hacer la unión con la de la tabla 2 \n",
    "                yield clave,linea\n",
    "            else:\n",
    "                linea.append(self.namefile) #Aquí estoy usando el nombre del archivo, pero puedo usar otro identificador\n",
    "                                        #como en el libro Dessign Pattern que usa A y B. Añadimos al registro el nombre\n",
    "                                        #del archivo.\n",
    "                clave=linea[0] #Esta es la otra clave común de la tabla 2\n",
    "                yield clave,linea\n",
    "    \n",
    "    def reducer_init(self):\n",
    "        self.listaA=[]\n",
    "        self.listaB=[]\n",
    "        \n",
    "    def reducer(self,key,values):\n",
    "        #Llenamos las dos listas\n",
    "        for valor in values:\n",
    "            if valor[len(valor)-1]==\"tablaA.csv\":\n",
    "                self.listaA.append(valor)\n",
    "            else:\n",
    "                self.listaB.append(valor)\n",
    "        \n",
    "        # Union interna ########################\n",
    "        if self.listaA and self.listaB:\n",
    "            for A in self.listaA:\n",
    "                for B in self.listaB:\n",
    "                    yield A, B\n",
    "        \n",
    "        # Union por la izquierda ####################\n",
    "        for A in self.listaA:\n",
    "            if self.listaB:\n",
    "                for B in self.listaB:\n",
    "                    yield A, B\n",
    "            else:\n",
    "                #Si la listaB está vacía\n",
    "                yield A, \"null\" \n",
    "                \n",
    "        # Union por la derecha ################\n",
    "        for B in self.listaB:\n",
    "            if self.listaA:\n",
    "                for A in self.listaA:\n",
    "                    yield A, B\n",
    "            else:\n",
    "                #Else, output A by itself\n",
    "                yield \"null\",B\n",
    "        \n",
    "        # Union completa ######################\n",
    "        # Si listaA no está vacía, commprobamos cada una de sus entradas\n",
    "        if self.listaA: \n",
    "        # Por cada entrada en la listaA\n",
    "            for A in self.listaA:\n",
    "            #Si la listaB no está vacía, unimos A con B\n",
    "                if self.listaB:\n",
    "                    for B in self.listaB:\n",
    "                        yield A, B\n",
    "                else:\n",
    "                #Si no es el caso, sacamos A con union nula\n",
    "                    yield A, \"null\"\n",
    "        else:\n",
    "        #En cambio si la listaA está vacía, sacamos solo los elementos de la listaB\n",
    "            for B in self.listaB:\n",
    "                yield \"null\", B\n",
    "        \n",
    "        # Antiunion ############################\n",
    "        #Si la listaA o la listaB están vacías\n",
    "        if not self.listaA or not self.listaB:\n",
    "\n",
    "        # Iteramos los valores vacíos de las dos listas\n",
    "            for A in self.listaA:\n",
    "                yield A, \"null\"\n",
    "            for B in self.listaB:\n",
    "                yield \"null\", B\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unionesVarias.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python unionesVarias.py tablaA.csv tablaB.csv > unionesVarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programa MapReduce para la unión interna de datos de dos tablas mediante una clave común. Este es de mi cosecha; habría que mejorarlo para las otras \n",
    "uniones: izquierda, derecha, completa y la antiunión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile reduceSideJoin.py\n",
    "#!/usr/bin/env python\n",
    "from mrjob.job import MRJob\n",
    "import re,os\n",
    "\n",
    "class reduceSideJoin(MRJob):\n",
    "    \n",
    "    #Función que limpia lo que el parámetro devuelve en forma \"file://nombre_fichero\" para dejarlo solo con el nombre \n",
    "    #del fichero: \"nombre_fichero\"\n",
    "    def limpiarNombreArchivo(self,archivo):\n",
    "        tamano=len(archivo)\n",
    "        return archivo[7:tamano]\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.namefile=self.limpiarNombreArchivo(os.getenv('map_input_file')) #Usamos el parámetro para saber que nos llega desde streaming\n",
    "        #map_input_file devuelve una cadena de caracteres correspondiente al archivo de entrada por el stream en formato:\n",
    "        # file://nombre_fichero\n",
    "        \n",
    "    def mapper(self,_,line):\n",
    "        linea=line.split(';')\n",
    "        encontrado=re.search('[a-zA-Z]',linea[0])#Para que no tenga en cuenta las cabeceras de las tablas\n",
    "        if encontrado==None:\n",
    "            if self.namefile==\"clientes.csv\":\n",
    "                #linea.append(self.namefile)#Añadimos al registro el nombre del archivo\n",
    "                clave=linea[0] #Esta clave es la común de la tabla 1, que me permite hacer la unión con la de la tabla 2 \n",
    "                yield clave,linea\n",
    "            else:\n",
    "                #linea.append(self.namefile) #Aquí estoy usando el nombre del archivo, pero puedo usar otro identificador\n",
    "                                        #como en el libro Dessign Pattern que usa A y B. Añadimos al registro el nombre\n",
    "                                        #del archivo.\n",
    "                clave=linea[6] #Esta es la otra clave común de la tabla 2. SI CAMBIAMOS LE ORIGEN DE DATOS ESTO HAY QUE VARIARLO\n",
    "                yield clave,linea\n",
    "    \n",
    "    \n",
    "    def reducer(self,key,values):\n",
    "        lista=[]\n",
    "        union=[]\n",
    "        for valor in values:\n",
    "            lista.append(valor)\n",
    "        \n",
    "        for elemento in range(1,len(lista)):\n",
    "            union.append(lista[0]+lista[elemento])\n",
    "            \n",
    "        for registro in union:\n",
    "            yield key,registro\n",
    "      \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    reduceSideJoin.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a investigar con una versión en la que no vamos a identificar el nombre del archivo que entra por Stream; vamos a ver si MRjob organiza las claves valor.\n",
    "RESULTADO: efectivamente MRJob organiza de forma autónoma cada clave con su registro correspondiente independientemente de las tablas. Lo que tenemos que tener en cuenta es donde está la clave común en cada una de las tablas, y aquí sí tenemos que conocer el nombre del archivo que está entrando, por que puede darse el caso que la clave esté en distintas columnas en cada una de las tablas implicadas en la unión. Habrá ocasiones en que podamos modificar la posición de la columna en el origen de datos, pero en otras ocasiones no será posible, que sería lo más comun esto último."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile pruebaJoin.py\n",
    "#!/usr/bin/env python\n",
    "from mrjob.job import MRJob\n",
    "import re,sys,os\n",
    "\n",
    "class pruebaJoin(MRJob):\n",
    "    \n",
    "    #Función que limpia lo que el parámetro devuelve en forma \"file://nombre_fichero\" para dejarlo solo con el nombre \n",
    "    #del fichero: \"nombre_fichero\"\n",
    "    def limpiarNombreArchivo(self,archivo):\n",
    "        tamano=len(archivo)\n",
    "        return archivo[7:tamano]\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.namefile=self.limpiarNombreArchivo(os.getenv('map_input_file')) #Usamos el parámetro para saber que nos llega desde streaming\n",
    "        #map_input_file devuelve una cadena de caracteres correspondiente al archivo de entrada por el stream en formato:\n",
    "        # file://nombre_fichero\n",
    "        \n",
    "    def mapper(self,_,line):\n",
    "        linea=line.split(';')\n",
    "        encontrado=re.search('[a-zA-Z]',linea[0])#Para que no tenga en cuenta las cabeceras de las tablas\n",
    "        if encontrado==None:\n",
    "            clave=linea[0] #Esta clave es la común de la tabla 1, que me permite hacer la unión con la de la tabla 2 \n",
    "            yield clave,linea\n",
    "            \n",
    "    \n",
    "    def reducer(self,key,values):\n",
    "        lista=[]\n",
    "        union=[]\n",
    "        for valor in values:\n",
    "            lista.append(valor)\n",
    "        \n",
    "        for elemento in range(1,len(lista)):\n",
    "            union.append(lista[0]+lista[elemento])\n",
    "            \n",
    "        for registro in union:\n",
    "            yield key,registro\n",
    "      \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    pruebaJoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pruebaJoin.py archivos_datos/tablaA.csv archivos_datos/tablaB.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo para comprobar que fichero entra en el map. Esto lo necesitaremos para desarrollar el patron de unión, por que dependiendo del fichero que entre, debermos de realizar distintas acciones.\n",
    "Usando un parámetro configurado (map_input_file), puedo saber que archivo Hadoop Streaming está leyendo\n",
    "de esta forma controlaremos lo que entra para desarrollar el patrón de unión y saber que clave/valor ha de ir a cada estructura, que luego usaremos en el reducer para hacer la unión. Mas informacón de parámetros configurados en:\n",
    "http://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html#Configured+Parameters\n",
    "EJEMPLO DE USO:\n",
    "https://www-it--swarm-dev.cdn.ampproject.org/v/s/www.it-swarm.dev/es/hadoop/como-obtener-el-nombre-del-archivo-de-entrada-en-el-mapeador-en-un-programa-hadoop/1042140842/amp/?usqp=mq331AQFKAGwASA%3D&amp_js_v=0.1#aoh=15964086144637&referrer=https%3A%2F%2Fwww.google.com&amp_tf=From%20%251%24s&ampshare=https%3A%2F%2Fwww.it-swarm.dev%2Fes%2Fhadoop%2Fcomo-obtener-el-nombre-del-archivo-de-entrada-en-el-mapeador-en-un-programa-hadoop%2F1042140842%2F\n",
    "Este ejemplo lo voy a coger como base para desarrollar el patrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile nombrefichero.py\n",
    "#!/usr/bin/env python\n",
    "from mrjob.job import MRJob\n",
    "import re,sys,fileinput,os\n",
    "\n",
    "class nombrefichero(MRJob):\n",
    "    def limpiarNombreArchivo(self,archivo):\n",
    "        encontradaBarra=False\n",
    "        tamano=len(archivo)\n",
    "        posicion=tamano-1\n",
    "        while encontradaBarra==False or posicion==0:\n",
    "            if archivo[posicion]==\"/\":\n",
    "                encontradaBarra=True\n",
    "                return archivo[posicion+1:tamano]\n",
    "            else:\n",
    "                posicion-=1\n",
    "        if posicion==0:\n",
    "            return archivo\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.namefile=self.limpiarNombreArchivo(os.getenv('map_input_file')) #Usamos el parámetro para saber que nos llega desde streaming\n",
    "        if controlArchivo!=\"\":\n",
    "            if controlArchivo!=self.namefile:\n",
    "                self.namefile2=self.namefile #Tenemos que compararlo con el otro u otros archivos que le metemos para\n",
    "                                                  # hacer la unión\n",
    "            else:\n",
    "                controlArchivo=self.namefile\n",
    "            \n",
    "        linea=[] #Declaramos una lista que le pasaremos al reducer con el valor.\n",
    "        \n",
    "    def mapper(self,_,line):\n",
    "        if self.namefile2!=self.namefile:      \n",
    "            linea=line.split(';')\n",
    "            yield self.namefile,linea\n",
    "        else:\n",
    "            linea=line.split(';')\n",
    "            yield \"Fichero nuevo: \" + self.namefile,linea\n",
    "        \n",
    "    \"\"\"def reducer(self, key, values):\n",
    "        for record in values:\n",
    "            yield key,record\"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nombrefichero.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python nombrefichero.py archivos_datos/tablaA.csv archivos_datos/tablaB.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
